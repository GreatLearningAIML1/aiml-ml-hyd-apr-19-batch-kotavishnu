{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "R8_Internal_Lab_Questions-HYD_AIML_Nov18.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NFfDTfhlaEI_"
      },
      "source": [
        "# Transfer Learning MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rNwbqCFRaEJC"
      },
      "source": [
        "* Train a simple convnet on the MNIST dataset the first 5 digits [0..4].\n",
        "* Freeze convolutional layers and fine-tune dense layers for the classification of digits [5..9]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IXrn3heBaEJa"
      },
      "source": [
        "### Import MNIST data and create 2 datasets with one dataset having digits from 0 to 4 and other from 5 to 9 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "poVVTgTMndNA"
      },
      "source": [
        "#### Import the mnist dataset from keras datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6x58DmS1p8j0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ab5d500a-15ff-4ba4-c88a-d90a2dbbf720"
      },
      "source": [
        "#Importing important modules\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "#Installing Tensorboard for Colab\n",
        "!pip install tensorboardcolab"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboardcolab in /usr/local/lib/python3.6/dist-packages (0.0.22)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bA53SCil55_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KMOJ66rpnh6C"
      },
      "source": [
        "#### Creating two datasets one with digits below 5 and one with 5 and above"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Xa33p7rdniFx",
        "colab": {}
      },
      "source": [
        "x_train_lt5 = x_train[y_train < 5]\n",
        "y_train_lt5 = y_train[y_train < 5]\n",
        "x_test_lt5 = x_test[y_test < 5]\n",
        "y_test_lt5 = y_test[y_test < 5]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MR7HViYavnR4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c3670255-c280-46bd-bfad-3b760d7ee0e5"
      },
      "source": [
        "set(y_train_lt5)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1, 2, 3, 4}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jansktH_uzDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_gt5 = x_train[y_train >= 5]\n",
        "y_train_gt5 = y_train[y_train >= 5] - 5  # make classes start at 0 for\n",
        "x_test_gt5 = x_test[y_test >= 5]         # np_utils.to_categorical\n",
        "y_test_gt5 = y_test[y_test >= 5] - 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3pdD62Fvewj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8b87562c-07f9-4d1d-caae-e335331782ec"
      },
      "source": [
        "set(y_train_gt5)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1, 2, 3, 4}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fVuxRq2v6L1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7fd9da7d-7cc0-4acd-ef10-1fce150cf655"
      },
      "source": [
        "set(y_train)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9qU14lYL9A5g"
      },
      "source": [
        "### Check \n",
        "\n",
        "Verify shapes of x_train, y_train, x_test and y_test for both the datasets with the below given shapes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9cx1YQbCor2r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "71521f6e-4a8d-4201-b0e4-ccd02e1ea950"
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z9OrszhJ0SgJ",
        "outputId": "886fcb9c-0018-418f-9f3c-be82ac7c49ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "print(x_train_lt5.shape)\n",
        "print(y_train_lt5.shape)\n",
        "print(x_test_lt5.shape)\n",
        "print(y_test_lt5.shape)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30596, 28, 28)\n",
            "(30596,)\n",
            "(5139, 28, 28)\n",
            "(5139,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sJswV4xk9jQS",
        "outputId": "faf479c9-0afc-4e56-bd44-8919e66861ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "print(x_train_gt5.shape)\n",
        "print(y_train_gt5.shape)\n",
        "print(x_test_gt5.shape)\n",
        "print(y_test_gt5.shape)"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(29404, 28, 28)\n",
            "(29404,)\n",
            "(4861, 28, 28)\n",
            "(4861,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cB9BPFzr9oDF"
      },
      "source": [
        "### Let us take only the dataset (x_train, y_train, x_test, y_test) for Integers 0 to 4 in MNIST\n",
        "### Reshape x_train and x_test to a 4 Dimensional array (channel = 1) to pass it into a Conv2D layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FlQRPfFzaEJx",
        "colab": {}
      },
      "source": [
        "x_train_lt5 = x_train_lt5.reshape(x_train_lt5.shape[0],28,28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7Np_Whbm8rc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5951cf44-33bc-4d39-9830-eca5514acd1b"
      },
      "source": [
        "x_train_lt5[0].shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ls85mt6BoRqS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test_lt5 = x_test_lt5.reshape(x_test_lt5.shape[0],28,28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDy5QUTWob0x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8d83bfdc-1f9c-4545-f332-fee00ec50aaf"
      },
      "source": [
        "x_test_lt5[0].shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jLQr-b3F-hw8"
      },
      "source": [
        "### Change into float32 datatype and Normalize x_train and x_test by dividing it by 255.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PlEZIAG5-g2I",
        "colab": {}
      },
      "source": [
        "x_train_lt5 = x_train_lt5.astype('float32')\n",
        "x_test_lt5 = x_test_lt5.astype('float32')\n",
        "\n",
        "#Normalizing the input\n",
        "x_train_lt5 /= 255.0\n",
        "x_test_lt5 /= 255.0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZSQrJFHgocNA"
      },
      "source": [
        "### Check\n",
        "\n",
        "Verify the shapes of the X_train and X_test with the shapes given below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0EdVW3SwpG5g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "faa5962c-84ad-43a5-eb79-4539dd85126c"
      },
      "source": [
        "print('x_train shape:', x_train_lt5.shape)\n",
        "print(x_train_lt5.shape[0], 'train samples')\n",
        "print(x_test_lt5.shape[0], 'test samples')"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (30596, 28, 28, 1)\n",
            "30596 train samples\n",
            "5139 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "utZ2zrpDoej9",
        "outputId": "fb709a6f-9096-41e5-c8fc-d6fa3a0e75a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print('X_train shape:', x_train_lt5.shape)\n",
        "print('X_test shape:', x_test_lt5.shape)"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape: (30596, 28, 28, 1)\n",
            "X_test shape: (5139, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6T1LxQwqIoJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "num_classes = 5\n",
        "epochs = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pytVBaw4-vMi"
      },
      "source": [
        "### Use One-hot encoding to divide y_train and y_test into required no of output classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V48xiua4-uUi",
        "colab": {}
      },
      "source": [
        "# convert class vectors to binary class matrices\n",
        "y_train_lt5 = keras.utils.to_categorical(y_train_lt5, num_classes)\n",
        "y_test_lt5 = keras.utils.to_categorical(y_test_lt5, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxahh6K3qP2a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5de96c64-a38b-4c8f-d7e0-461e4ab19009"
      },
      "source": [
        "set(y_train_lt5)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1, 2, 3, 4}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOWE7Pn8rcMg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "#Keras expects data to be in the format (N_E.N_H,N_W,N_C)\n",
        "#N_E = Number of Examples, N_H = height, N_W = Width, N_C = Number of Channels.\n",
        "x_train_lt5 = x_train_lt5.reshape(x_train_lt5.shape[0], img_rows, img_cols, 1)\n",
        "x_test_lt5 = x_test_lt5.reshape(x_test_lt5.shape[0], img_rows, img_cols, 1)\n",
        "input_shape = (img_rows, img_cols, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "elPkI44g_C2b"
      },
      "source": [
        "### Build a sequential model with 2 Convolutional layers with 32 kernels of size (3,3) followed by a Max pooling layer of size (2,2) followed by a drop out layer to be trained for classification of digits 0-4  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nOeyulnRp1Hp",
        "colab": {}
      },
      "source": [
        "#Initialize the model\n",
        "model = Sequential()\n",
        "\n",
        "#Add a Convolutional Layer with 32 filters of size 3X3 and activation function as 'ReLU' \n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "\n",
        "#Add a Convolutional Layer with 64 filters of size 3X3 and activation function as 'ReLU' \n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "#Add a MaxPooling Layer of size 2X2 \n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "#Apply Dropout with 0.25 probability \n",
        "model.add(Dropout(0.25))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MU09mm9F89gO",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sJQaycRO_3Au"
      },
      "source": [
        "### Post that flatten the data and add 2 Dense layers with 128 neurons and neurons = output classes with activation = 'relu' and 'softmax' respectively. Add dropout layer inbetween if necessary  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vOZeRbK7t9AT",
        "colab": {}
      },
      "source": [
        "#Flatten the layer\n",
        "model.add(Flatten())\n",
        "\n",
        "#Add Fully Connected Layer with 128 units and activation function as 'ReLU'\n",
        "model.add(Dense(128, activation='relu'))\n",
        "#Apply Dropout with 0.5 probability \n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "#Add Fully Connected Layer with 10 units and activation function as 'softmax'\n",
        "model.add(Dense(num_classes, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "my1P09bxAv8H"
      },
      "source": [
        "### Print the training and test accuracy for 5 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yf7F8Gdutbf0",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.losses import categorical_crossentropy\n",
        "\n",
        "#To use adam optimizer for learning weights with learning rate = 0.001\n",
        "optimizer = Adam(lr=0.001)\n",
        "#Set the loss function and optimizer for the model training\n",
        "model.compile(loss=categorical_crossentropy,\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ly9bnbyyrHH_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "e2f8bf70-bed8-4882-8a6a-11b5cd51a281"
      },
      "source": [
        "#Import tensorboardcolab modules for creating a tensorboard call back which will passed in model.fit function.\n",
        "from tensorboardcolab import TensorBoardColab, TensorBoardColabCallback\n",
        "\n",
        "#Tensorboard callback is going to be added to model.fit function to draw graphs of loss values after every epoch\n",
        "tbc = TensorBoardColab()"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "http://c5246f93.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-e2XpaMrKsT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Adding Early stopping callback to the fit function is going to stop the training,\n",
        "#if the val_loss is not going to change even '0.001' for more than 10 continous epochs\n",
        "import os\n",
        "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=10)\n",
        "\n",
        "#Adding Model Checkpoint callback to the fit function is going to save the weights whenever val_loss achieves a new low value. \n",
        "#Hence saving the best weights occurred during training\n",
        "\n",
        "model_checkpoint =  ModelCheckpoint('mnist_cnn_checkpoint_{epoch:02d}_loss{val_loss:.4f}.h5',\n",
        "                                                           monitor='val_loss',\n",
        "                                                           verbose=1,\n",
        "                                                           save_best_only=True,\n",
        "                                                           save_weights_only=True,\n",
        "                                                           mode='auto',\n",
        "                                                           period=1)\n",
        "\n",
        "checkpoint_path = \"mnist.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create a callback that saves the model's weights\n",
        "cp_callback = ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hF3IrbnrNIj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "outputId": "a60c5c97-c045-49bb-9d23-d32a6e18ba8f"
      },
      "source": [
        "#Training on the dataset and adding the all the callbacks to the fit function.\n",
        "#Once the training starts, results start appearing on Tensorboard after 1 epoch\n",
        "model.fit(x_train_lt5, y_train_lt5,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test_lt5, y_test_lt5),\n",
        "          callbacks=[TensorBoardColabCallback(tbc),early_stopping,model_checkpoint,cp_callback])"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 30596 samples, validate on 5139 samples\n",
            "Epoch 1/5\n",
            "30596/30596 [==============================] - 4s 147us/step - loss: 0.0308 - acc: 0.9899 - val_loss: 0.0095 - val_acc: 0.9969\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.00947, saving model to mnist_cnn_checkpoint_01_loss0.0095.h5\n",
            "\n",
            "Epoch 00001: saving model to mnist.ckpt\n",
            "Epoch 2/5\n",
            "30596/30596 [==============================] - 4s 145us/step - loss: 0.0189 - acc: 0.9944 - val_loss: 0.0092 - val_acc: 0.9963\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.00947 to 0.00919, saving model to mnist_cnn_checkpoint_02_loss0.0092.h5\n",
            "\n",
            "Epoch 00002: saving model to mnist.ckpt\n",
            "Epoch 3/5\n",
            "30596/30596 [==============================] - 4s 144us/step - loss: 0.0174 - acc: 0.9943 - val_loss: 0.0063 - val_acc: 0.9984\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.00919 to 0.00627, saving model to mnist_cnn_checkpoint_03_loss0.0063.h5\n",
            "\n",
            "Epoch 00003: saving model to mnist.ckpt\n",
            "Epoch 4/5\n",
            "30596/30596 [==============================] - 4s 145us/step - loss: 0.0128 - acc: 0.9956 - val_loss: 0.0072 - val_acc: 0.9977\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.00627\n",
            "\n",
            "Epoch 00004: saving model to mnist.ckpt\n",
            "Epoch 5/5\n",
            "30596/30596 [==============================] - 4s 143us/step - loss: 0.0116 - acc: 0.9961 - val_loss: 0.0047 - val_acc: 0.9977\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.00627 to 0.00475, saving model to mnist_cnn_checkpoint_05_loss0.0047.h5\n",
            "\n",
            "Epoch 00005: saving model to mnist.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6feb1611d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XguemlnNtD9l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "87e9553b-da00-46ff-dd27-a898685b394a"
      },
      "source": [
        "#Testing the model on test set\n",
        "score = model.evaluate(x_test_lt5, y_test_lt5)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5139/5139 [==============================] - 1s 110us/step\n",
            "Test loss: 0.003304791110768503\n",
            "Test accuracy: 0.9990270480638257\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvoMTAS-6qmS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "35359cde-6fcc-4f14-df5a-3d183e3c78a0"
      },
      "source": [
        "!ls {checkpoint_dir}"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Graph\t\t\t\t       mnist_cnn_checkpoint_03_loss0.0076.h5\n",
            "mnist.ckpt\t\t\t       mnist_cnn_checkpoint_03_loss0.0101.h5\n",
            "mnist_cnn_checkpoint_01_loss0.0095.h5  mnist_cnn_checkpoint_04_loss0.0053.h5\n",
            "mnist_cnn_checkpoint_01_loss0.0147.h5  mnist_cnn_checkpoint_04_loss0.0059.h5\n",
            "mnist_cnn_checkpoint_01_loss0.0155.h5  mnist_cnn_checkpoint_05_loss0.0044.h5\n",
            "mnist_cnn_checkpoint_01_loss0.0199.h5  mnist_cnn_checkpoint_05_loss0.0047.h5\n",
            "mnist_cnn_checkpoint_02_loss0.0085.h5  mnist_cnn_checkpoint_08_loss0.0054.h5\n",
            "mnist_cnn_checkpoint_02_loss0.0092.h5  mnist_cnn_checkpoint_10_loss0.0033.h5\n",
            "mnist_cnn_checkpoint_02_loss0.0116.h5  sample_data\n",
            "mnist_cnn_checkpoint_03_loss0.0063.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "z78o3WIjaEJ3"
      },
      "source": [
        "### Use the model trained on 0 to 4 digit classification and train it on the dataset which has digits 5 to 9  (Using Transfer learning keeping only the dense layers to be trainable)\n",
        "\n",
        "### Make only the dense layers to be trainable and convolutional layers to be non-trainable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DqRYoYlXCw_L"
      },
      "source": [
        "#### Check model summary to see model layer names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "brN7VZHFaEJ4",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k24fHhlUslH6",
        "outputId": "9843f5be-c745-4f2a-fc26-a9a267b39fdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        }
      },
      "source": [
        "for layers in model.layers:\n",
        "    print(layers.name)\n",
        "    if('dense' not in layers.name):\n",
        "        layers.trainable = False\n",
        "        print(layers.name + 'is not trainable\\n')\n",
        "    if('dense' in layers.name):\n",
        "        print(layers.name + ' is trainable\\n')"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv2d_5\n",
            "conv2d_5is not trainable\n",
            "\n",
            "conv2d_6\n",
            "conv2d_6is not trainable\n",
            "\n",
            "max_pooling2d_3\n",
            "max_pooling2d_3is not trainable\n",
            "\n",
            "dropout_5\n",
            "dropout_5is not trainable\n",
            "\n",
            "flatten_3\n",
            "flatten_3is not trainable\n",
            "\n",
            "dense_5\n",
            "dense_5 is trainable\n",
            "\n",
            "dropout_6\n",
            "dropout_6is not trainable\n",
            "\n",
            "dense_6\n",
            "dense_6 is trainable\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8908wI0itQZ7"
      },
      "source": [
        "### Do the required preprocessing for `x_train_gt5` also same as `x_train_lt5` and for `y_train_gt5` same as `y_train_lt5`\n",
        "\n",
        "1. Reshape\n",
        "2. Change to float32 datatype\n",
        "3. Normalize (dividing with 255)\n",
        "4. y_train and y_test Convert into one-hot vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnYFG9AotdPh",
        "colab_type": "text"
      },
      "source": [
        "Reshape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lCFcYHTm6-cE",
        "colab": {}
      },
      "source": [
        "x_train_gt5 = x_train_gt5.reshape(x_train_gt5.shape[0],28,28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bv5AvjOtvLds",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8a4efbcb-ce2e-4401-c9f9-8c109603bb08"
      },
      "source": [
        "x_train_gt5.shape"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(29404, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUdU70QkuaZv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "52bacad9-eedf-41dd-dfd3-8e698cad0604"
      },
      "source": [
        "set(y_train_gt5)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1, 2, 3, 4}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZ3ecXFXt405",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test_gt5 = x_test_gt5.reshape(x_test_gt5.shape[0],28,28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eh64PFKmtzEz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Change to Float and Normalize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGTUuxYzthlX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_gt5 = x_train_gt5.astype('float32')\n",
        "x_test_gt5 = x_test_gt5.astype('float32')\n",
        "\n",
        "#Normalizing the input\n",
        "x_train_gt5 /= 255.0\n",
        "x_test_gt5 /= 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tNaRUZnuNQy",
        "colab_type": "text"
      },
      "source": [
        "OneHot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTek4E2NuMrm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert class vectors to binary class matrices\n",
        "y_train_gt5 = keras.utils.to_categorical(y_train_gt5, num_classes)\n",
        "y_test_gt5 = keras.utils.to_categorical(y_test_gt5, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1SYDxFsvuAVE"
      },
      "source": [
        "### Check\n",
        "\n",
        "Verify the shapes with the given below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wJc7PvvCuGVa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "beaa1d02-de50-4044-fd1f-a13deb5c3e46"
      },
      "source": [
        "!ls {checkpoint_dir}"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Graph\t\t\t\t       mnist_cnn_checkpoint_03_loss0.0076.h5\n",
            "mnist.ckpt\t\t\t       mnist_cnn_checkpoint_03_loss0.0101.h5\n",
            "mnist_cnn_checkpoint_01_loss0.0095.h5  mnist_cnn_checkpoint_04_loss0.0053.h5\n",
            "mnist_cnn_checkpoint_01_loss0.0147.h5  mnist_cnn_checkpoint_04_loss0.0059.h5\n",
            "mnist_cnn_checkpoint_01_loss0.0155.h5  mnist_cnn_checkpoint_05_loss0.0044.h5\n",
            "mnist_cnn_checkpoint_01_loss0.0199.h5  mnist_cnn_checkpoint_05_loss0.0047.h5\n",
            "mnist_cnn_checkpoint_02_loss0.0085.h5  mnist_cnn_checkpoint_08_loss0.0054.h5\n",
            "mnist_cnn_checkpoint_02_loss0.0092.h5  mnist_cnn_checkpoint_10_loss0.0033.h5\n",
            "mnist_cnn_checkpoint_02_loss0.0116.h5  sample_data\n",
            "mnist_cnn_checkpoint_03_loss0.0063.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvPMM48s7gA4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The pre-trained weights must exist in a folder called \"data\" in the current folder\n",
        "model.load_weights('mnist_cnn_checkpoint_10_loss0.0033.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5AANrUvVt_6U",
        "outputId": "231231ba-7c4f-4aa4-a5c0-68bb5edf97f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "print(x_train_gt5.shape)\n",
        "print(y_train_gt5.shape)\n",
        "print(x_test_gt5.shape)\n",
        "print(y_test_gt5.shape)"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(29404, 28, 28, 1)\n",
            "(29404, 5)\n",
            "(4861, 28, 28, 1)\n",
            "(4861, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SoDozqghCJZ4"
      },
      "source": [
        "## Print the accuracy for classification of digits 5 to 9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9fCxgb5s49Cj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "outputId": "f0fe1861-ae29-4713-838f-116bf133e637"
      },
      "source": [
        "#Training on the dataset and adding the all the callbacks to the fit function.\n",
        "#Once the training starts, results start appearing on Tensorboard after 1 epoch\n",
        "model.fit(x_train_gt5, y_train_gt5,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test_gt5, y_test_gt5),\n",
        "          callbacks=[early_stopping,model_checkpoint])"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 29404 samples, validate on 4861 samples\n",
            "Epoch 1/5\n",
            "  896/29404 [..............................] - ETA: 5s - loss: 3.1050 - acc: 0.5335"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "29404/29404 [==============================] - 4s 146us/step - loss: 0.2395 - acc: 0.9408 - val_loss: 0.0396 - val_acc: 0.9858\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.00475\n",
            "Epoch 2/5\n",
            "29404/29404 [==============================] - 4s 142us/step - loss: 0.0590 - acc: 0.9818 - val_loss: 0.0278 - val_acc: 0.9916\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.00475\n",
            "Epoch 3/5\n",
            "29404/29404 [==============================] - 4s 142us/step - loss: 0.0419 - acc: 0.9870 - val_loss: 0.0254 - val_acc: 0.9918\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.00475\n",
            "Epoch 4/5\n",
            "29404/29404 [==============================] - 4s 144us/step - loss: 0.0308 - acc: 0.9903 - val_loss: 0.0229 - val_acc: 0.9932\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.00475\n",
            "Epoch 5/5\n",
            "29404/29404 [==============================] - 4s 144us/step - loss: 0.0266 - acc: 0.9921 - val_loss: 0.0220 - val_acc: 0.9947\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.00475\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6feb879f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LRWizZIpCUKg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "476b17c0-af69-4b6f-a50a-8e46a7fb693d"
      },
      "source": [
        "#Testing the model on test set\n",
        "score = model.evaluate(x_test_gt5, y_test_gt5)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4861/4861 [==============================] - 1s 107us/step\n",
            "Test loss: 0.022041278657298862\n",
            "Test accuracy: 0.994651306315573\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0zDuRecXzEtr"
      },
      "source": [
        "# Text classification using TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xMPlEJhHzb6P"
      },
      "source": [
        "###  Load the dataset from sklearn.datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Fe-B59u3zHNb",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PRrMemVQzbHU",
        "colab": {}
      },
      "source": [
        "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-sZX0UbJzmg5"
      },
      "source": [
        "### Training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CITr_5aXziJ2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d0cf989e-b19b-40d4-acb8-fc53dfa70ec1"
      },
      "source": [
        "twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xcESc5QXzr6p"
      },
      "source": [
        "### Test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ysInblUMzpvl",
        "colab": {}
      },
      "source": [
        "twenty_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DriL2yZ50DQq"
      },
      "source": [
        "###  a.  You can access the values for the target variable using .target attribute \n",
        "###  b. You can access the name of the class in the target variable with .target_names\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vlUuai99z1hX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ba96c567-9678-4007-948a-5c6419e9a60c"
      },
      "source": [
        "twenty_train.target"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 3, ..., 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VEKzaDfSz5E-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2438acac-30b4-41c0-bc0e-f1e50a38e878"
      },
      "source": [
        "twenty_train.target_names"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoExArom0a7u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "12cfc3b8-538f-49af-c67b-f405fe2b1856"
      },
      "source": [
        "twenty_train.target"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 3, ..., 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "clBMKHzC0_N1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "3b779d47-2d76-46ec-89be-e2491043a7ec"
      },
      "source": [
        "twenty_train.data[0:5]"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['From: sd345@city.ac.uk (Michael Collier)\\nSubject: Converting images to HP LaserJet III?\\nNntp-Posting-Host: hampton\\nOrganization: The City University\\nLines: 14\\n\\nDoes anyone know of a good way (standard PC application/PD utility) to\\nconvert tif/img/tga files into LaserJet III format.  We would also like to\\ndo the same, converting to HPGL (HP plotter) files.\\n\\nPlease email any response.\\n\\nIs this the correct group?\\n\\nThanks in advance.  Michael.\\n-- \\nMichael Collier (Programmer)                 The Computer Unit,\\nEmail: M.P.Collier@uk.ac.city                The City University,\\nTel: 071 477-8000 x3769                      London,\\nFax: 071 477-8565                            EC1V 0HB.\\n',\n",
              " \"From: ani@ms.uky.edu (Aniruddha B. Deglurkar)\\nSubject: help: Splitting a trimming region along a mesh \\nOrganization: University Of Kentucky, Dept. of Math Sciences\\nLines: 28\\n\\n\\n\\n\\tHi,\\n\\n\\tI have a problem, I hope some of the 'gurus' can help me solve.\\n\\n\\tBackground of the problem:\\n\\tI have a rectangular mesh in the uv domain, i.e  the mesh is a \\n\\tmapping of a 3d Bezier patch into 2d. The area in this domain\\n\\twhich is inside a trimming loop had to be rendered. The trimming\\n\\tloop is a set of 2d Bezier curve segments.\\n\\tFor the sake of notation: the mesh is made up of cells.\\n\\n\\tMy problem is this :\\n\\tThe trimming area has to be split up into individual smaller\\n\\tcells bounded by the trimming curve segments. If a cell\\n\\tis wholly inside the area...then it is output as a whole ,\\n\\telse it is trivially rejected. \\n\\n\\tDoes any body know how thiss can be done, or is there any algo. \\n\\tsomewhere for doing this.\\n\\n\\tAny help would be appreciated.\\n\\n\\tThanks, \\n\\tAni.\\n-- \\nTo get irritated is human, to stay cool, divine.\\n\",\n",
              " \"From: djohnson@cs.ucsd.edu (Darin Johnson)\\nSubject: Re: harrassed at work, could use some prayers\\nOrganization: =CSE Dept., U.C. San Diego\\nLines: 63\\n\\n(Well, I'll email also, but this may apply to other people, so\\nI'll post also.)\\n\\n>I've been working at this company for eight years in various\\n>engineering jobs.  I'm female.  Yesterday I counted and realized that\\n>on seven different occasions I've been sexually harrassed at this\\n>company.\\n\\n>I dreaded coming back to work today.  What if my boss comes in to ask\\n>me some kind of question...\\n\\nYour boss should be the person bring these problems to.  If he/she\\ndoes not seem to take any action, keep going up higher and higher.\\nSexual harrassment does not need to be tolerated, and it can be an\\nenormous emotional support to discuss this with someone and know that\\nthey are trying to do something about it.  If you feel you can not\\ndiscuss this with your boss, perhaps your company has a personnel\\ndepartment that can work for you while preserving your privacy.  Most\\ncompanies will want to deal with this problem because constant anxiety\\ndoes seriously affect how effectively employees do their jobs.\\n\\nIt is unclear from your letter if you have done this or not.  It is\\nnot inconceivable that management remains ignorant of employee\\nproblems/strife even after eight years (it's a miracle if they do\\nnotice).  Perhaps your manager did not bring to the attention of\\nhigher ups?  If the company indeed does seem to want to ignore the\\nentire problem, there may be a state agency willing to fight with\\nyou.  (check with a lawyer, a women's resource center, etc to find out)\\n\\nYou may also want to discuss this with your paster, priest, husband,\\netc.  That is, someone you know will not be judgemental and that is\\nsupportive, comforting, etc.  This will bring a lot of healing.\\n\\n>So I returned at 11:25, only to find that ever single\\n>person had already left for lunch.  They left at 11:15 or so.  No one\\n>could be bothered to call me at the other building, even though my\\n>number was posted.\\n\\nThis happens to a lot of people.  Honest.  I believe it may seem\\nto be due to gross insensitivity because of the feelings you are\\ngoing through.  People in offices tend to be more insensitive while\\nworking than they normally are (maybe it's the hustle or stress or...)\\nI've had this happen to me a lot, often because they didn't realize\\nmy car was broken, etc.  Then they will come back and wonder why I\\ndidn't want to go (this would tend to make me stop being angry at\\nbeing ignored and make me laugh).  Once, we went off without our\\nboss, who was paying for the lunch :-)\\n\\n>For this\\n>reason I hope good Mr. Moderator allows me this latest indulgence.\\n\\nWell, if you can't turn to the computer for support, what would\\nwe do?  (signs of the computer age :-)\\n\\nIn closing, please don't let the hateful actions of a single person\\nharm you.  They are doing it because they are still the playground\\nbully and enjoy seeing the hurt they cause.  And you should not\\naccept the opinions of an imbecile that you are worthless - much\\nwiser people hold you in great esteem.\\n-- \\nDarin Johnson\\ndjohnson@ucsd.edu\\n  - Luxury!  In MY day, we had to make do with 5 bytes of swap...\\n\",\n",
              " 'From: s0612596@let.rug.nl (M.M. Zwart)\\nSubject: catholic church poland\\nOrganization: Faculteit der Letteren, Rijksuniversiteit Groningen, NL\\nLines: 10\\n\\nHello,\\n\\nI\\'m writing a paper on the role of the catholic church in Poland after 1989. \\nCan anyone tell me more about this, or fill me in on recent books/articles(\\nin english, german or french). Most important for me is the role of the \\nchurch concerning the abortion-law, religious education at schools,\\nbirth-control and the relation church-state(government). Thanx,\\n\\n                                                 Masja,\\n\"M.M.Zwart\"<s0612596@let.rug.nl>\\n',\n",
              " 'From: stanly@grok11.columbiasc.ncr.com (stanly)\\nSubject: Re: Elder Brother\\nOrganization: NCR Corp., Columbia SC\\nLines: 15\\n\\nIn article <Apr.8.00.57.41.1993.28246@athos.rutgers.edu> REXLEX@fnal.gov writes:\\n>In article <Apr.7.01.56.56.1993.22824@athos.rutgers.edu> shrum@hpfcso.fc.hp.com\\n>Matt. 22:9-14 \\'Go therefore to the main highways, and as many as you find\\n>there, invite to the wedding feast.\\'...\\n\\n>hmmmmmm.  Sounds like your theology and Christ\\'s are at odds. Which one am I \\n>to believe?\\n\\nIn this parable, Jesus tells the parable of the wedding feast. \"The kingdom\\nof heaven is like unto a certain king which made a marriage for his son\".\\nSo the wedding clothes were customary,  and \"given\" to those who \"chose\" to\\nattend.  This man \"refused\" to wear the clothes.  The wedding clothes are\\nequalivant to the \"clothes of righteousness\".  When Jesus died for our sins,\\nthose \"clothes\" were then provided.  Like that man, it is our decision to\\nput the clothes on.\\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hTz4EaN_1WGc"
      },
      "source": [
        "### Now with dependent and independent data available for both train and test datasets, using TfidfVectorizer fit and transform the training data and test data and get the tfidf features for both"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H5G477f81C0Z",
        "colab": {}
      },
      "source": [
        "# define X and y\n",
        "X = twenty_train.data\n",
        "y = twenty_train.target\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEjRvfT02R3l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cd2a7151-b6b4-4246-c4a5-318008a59d6e"
      },
      "source": [
        "y"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 3, ..., 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4zwqh1f0zIu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# split the new DataFrame into training and testing sets [Default test size = 25%]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tp_fDINJ1t4L"
      },
      "source": [
        "### Use logisticRegression with tfidf features as input and targets as output and train the model and report the train and test accuracy score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "THlN2b5d1yQp",
        "colab": {}
      },
      "source": [
        "# define a function that accepts a vectorizer and calculates the accuracy\n",
        "def tokenize_test(vect):\n",
        "    X_train_dtm = vect.fit_transform(X_train)\n",
        "    print('Features: ', X_train_dtm.shape[1])\n",
        "    X_test_dtm = vect.transform(X_test)\n",
        "    print('For NB:')\n",
        "    nb = MultinomialNB()\n",
        "    nb.fit(X_train_dtm, y_train)\n",
        "    train_pred=nb.predict(X_train_dtm)\n",
        "    print('Train Accuracy:',metrics.accuracy_score(y_train,train_pred))\n",
        "    y_pred_class = nb.predict(X_test_dtm)\n",
        "    print('Test Accuracy: ', metrics.accuracy_score(y_test, y_pred_class))\n",
        "    \n",
        "    # use logistic regression with all features\n",
        "    print('Logistic Regression.....')\n",
        "    logreg = LogisticRegression(C=1e9)\n",
        "    logreg.fit(X_train_dtm, y_train)\n",
        "    train_pred = logreg.predict(X_train_dtm)\n",
        "    print('Train Accuracy:',metrics.accuracy_score(y_train,train_pred))\n",
        "    y_pred_class = logreg.predict(X_test_dtm)\n",
        "    print('Test Accuracy: ', metrics.accuracy_score(y_test, y_pred_class))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfwMTXyv2nup",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "d681db83-5d8e-4c5d-b0f0-4fa21c53b43c"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "# include 1-grams and 2-grams\n",
        "vect = CountVectorizer(ngram_range=(1, 2))\n",
        "tokenize_test(vect)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features:  239842\n",
            "For NB:\n",
            "Train Accuracy: 0.9994089834515366\n",
            "Test Accuracy:  0.9610619469026549\n",
            "Logistic Regression.....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy: 1.0\n",
            "Test Accuracy:  0.952212389380531\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-VYjlH73EuI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "bce45095-edac-4f3e-98f8-981755b9b262"
      },
      "source": [
        "# remove English stop words\n",
        "vect = CountVectorizer(stop_words='english')\n",
        "tokenize_test(vect)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features:  30227\n",
            "For NB:\n",
            "Train Accuracy: 0.9988179669030733\n",
            "Test Accuracy:  0.968141592920354\n",
            "Logistic Regression.....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy: 1.0\n",
            "Test Accuracy:  0.9451327433628318\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}